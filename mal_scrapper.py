#!/usr.bin/env python3
##
# Dakara Project
#

import json, re, requests


def get_artists(tags):
    """
    Find and save the artists of an anime theme by scrapping MyAnimeList.
    The scrapped data will be cached to reduce later parsing times.

    tags is a dictionnary generated by anime_parse.parse_file_name (will be edited with the found artists)
    """
    
    # We first load the local data
    json_file = open('mal_scrapper.json', 'r')
    saved_data = json.load(json_file)
    json_file.close()

    # If we don't find the anime, let's scrap MAL
    if tags['title_work'] not in saved_data[0]: # We check
        scrap_anime(tags['title_work'], saved_data)

    # If we find the anime, let's get the artists
    if tags['title_work'] in saved_data[0]:
        if tags['link_nb'] == '':
            return saved_data[0][tags['title_work']][tags['link_type']][0]
        else:
            return saved_data[0][tags['title_work']][tags['link_type']][int(tags['link_nb'])-1]


def scrap_anime(name, data):
    """
    This function does the actual scrapping and saves it in data.
    """

    # First steap: finding the page of the anime, using the search engine
    r = requests.get('https://myanimelist.net/anime.php?q=' + name)
    result = r.text
    found = {}

    i = 0
    N = 10 # Max number of results kept
    for entry in result.split('\n'):
        if '<a class="hoverinfo_trigger fw-b fl-l"' in entry:
            if i >= N: # We won't keep more than N entries
                break;
            i = i + 1

            anime = re.sub('^.*<strong>([^"]*)</strong>.*$', r'\1', entry)
            link = re.sub('^.*" href="([^"]*)".*$', r'\1', entry) 
            found[anime] = link # We store the result and continue

            if anime == name: # If we find a perfect match, that's great!
                break
    
    if anime != name: # If we didn't get a perfect match, we will ask the user
        i = 0
        for anime in found:
            print(str(i) + ": " + anime)
            i = i + 1
        match_index = input(name + ": which is the right one? ")
        if (int(match_index) >= N): # No match, no need to continue
            return

        anime = list(found)[int(match_index)] # Dictionaries are ordered since Python 3.6, so it should be fine >.>

    # Second step: getting the page of the found anime
    r = requests.get(found[anime])
    result = r.text
    op = []
    ed = []

    # Third step: extracting the artists
    for line in result.split('\n'):
        if '<div class="theme-songs js-theme-songs opnening">' in line:
            op = extract_artists(line)
        if '<div class="theme-songs js-theme-songs ending">' in line:
            ed = extract_artists(line)

    # Fourth step: saving the data locally
    data[0][name] = {}
    data[0][name]['OP'] = op
    data[0][name]['ED'] = ed

    json_file = open('mal_scrapper.json', 'w')
    json.dump(data, json_file)
    json_file.close()


def extract_artists(line):
    """
    When scrapping, extracts the artists from the html line that contains them.
    """
    artists = []
    for entry in line.split('<br>'): # For each theme
        if entry != "</div>": # This ignores the last entry
            temp_artists = []
            found = re.sub('^.*&quot; by ([^<]*)</span>$', r'\1', entry) # This gets the artists
            found = re.sub(' \(ep.*\)$', '', found) # This removes the information about the episodes
            found = found.encode("ascii", errors="ignore").decode() # This removes the non ASCII characters
            found = re.sub(' \( *\)', '', found) # This removes the parenthesis with spaces only
            for artist in found.split(', '): # Here we split if there are multiple artists
                artist = re.sub('^.* \((.*)\)', r'\1', artist) # For the cases where the real artist is in parenthesis
                temp_artists.append(artist)
            artists.append(temp_artists)

    return artists
